{
  "provider": "ollama",
  "endpoint": "http://localhost:11434",
  "model": "codellama:13b",
  "temperature": 0.3,
  "maxTokens": 1000,
  "timeout": 30000
}
